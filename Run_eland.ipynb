{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running \"ELAND\"\n",
    "This notebook runs what is currently the very bare bones of ELAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries & scripts\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bihidef\n",
    "from netZooPy import sambar\n",
    "from goatools import obo_parser\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "from pybiomart import Dataset\n",
    "import eland\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from eland import filter_panda, process_panda \n",
    "\n",
    "#set working directory\n",
    "os.chdir(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some params\n",
    "#breast\n",
    "#panda_file = \"gtex_breast_panda.txt\"\n",
    "#panda_edgelist = \"gtex_breast_edgelist.txt\"\n",
    "#prior_file = \"motif_prior_names_2024_filtered.txt\"\n",
    "#edgelist_fil = \"gtex_breast_edgelist_filtered.csv\"\n",
    "#edgelist_fil = \"brca_fil_edges.csv\"\n",
    "#edgelist_top = \"gtex_subset_first_half.csv\"\n",
    "#edgelist_end = \"gtex_subset_end.csv\"\n",
    "#edgelist_end2 = \"gtex_subset_end2.csv\"\n",
    "\n",
    "# uterus\n",
    "panda_file = \"gtex_uterus_panda.txt\"\n",
    "panda_edgelist = \"gtex_uterus_edgelist.txt\"\n",
    "prior_file = \"motif_prior_names_2024_filtered.txt\"\n",
    "edgelist_fil = \"gtex_uterus_edgelist_filtered.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read(\"gtex_uterus_panda.txt\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/kuijjerarea/romana/eland/ELAND/eland/process_panda.py:18: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(input_file, delim_whitespace=True, header=None)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The input file does not have at least four columns.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# filter network\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_panda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_edge_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpanda_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanda_edgelist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m fil_edges \u001b[38;5;241m=\u001b[39m filter_panda\u001b[38;5;241m.\u001b[39mfilter_edges(prior_file\u001b[38;5;241m=\u001b[39mprior_file ,panda_file\u001b[38;5;241m=\u001b[39mpanda_edgelist)\n\u001b[1;32m      4\u001b[0m fil_edges\u001b[38;5;241m.\u001b[39mto_csv(edgelist_fil, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/storage/kuijjerarea/romana/eland/ELAND/eland/process_panda.py:22\u001b[0m, in \u001b[0;36mprocess_edge_list\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure there are sufficient columns in the DataFrame\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input file does not have at least four columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Remove the third column\u001b[39;00m\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: The input file does not have at least four columns."
     ]
    }
   ],
   "source": [
    "# filter network\n",
    "process_panda.process_edge_list(panda_file, panda_edgelist)\n",
    "fil_edges = filter_panda.filter_edges(prior_file=prior_file ,panda_file=panda_edgelist)\n",
    "fil_edges.to_csv(edgelist_fil, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bihidef\n",
    "# this will save a bunch of files in the working directory\n",
    "bihidef.bihidef(edgelist_fil, maxres=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bihidef for UCEC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get communities\n",
    "sign = pd.read_csv(\"pvg.nodes\", delimiter = \"\\t\")\n",
    "\n",
    "# Extract clusters\n",
    "clusters = sign.iloc[:, 0].astype(str)\n",
    "clusters = clusters.str[7:]  # removing the first 7 characters\n",
    "clusters = np.array([list(map(int, c.split('-'))) for c in clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select clusters with sizes between selected range\n",
    "# set range\n",
    "min_size = 10\n",
    "max_size = 200\n",
    "\n",
    "fil_clust = sign[(sign.iloc[:,1] >= min_size) & (sign.iloc[:,1] <= max_size)]\n",
    "\n",
    "#write to gmt\n",
    "eland.gmt_from_bihidef(fil_clust, \"fil_comm.gmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run sambar with bihidef communities\n",
    "sambar.sambar(mut_file=\"../data/BRCAmutMatrixFinal.csv\",\n",
    "                            esize_file=\"../data/esizef.csv\",\n",
    "                            genes_file=\"../data/genes.txt\",\n",
    "                            gmtfile=\"fil_comm.gmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sambar with pathways\n",
    "sambar.sambar(mut_file=\"../data/BRCAmutMatrixFinal.csv\",\n",
    "                            esize_file=\"../data/esizef.csv\",\n",
    "                            genes_file=\"../data/genes.txt\",\n",
    "                            gmtfile=\"../data/c2.cp.v2024.1.Hs.symbols.gmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go enrichment for selected communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GTEx gene annotation file\n",
    "anno = pd.read_csv(\"../data/GTEx_gene_names.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# Column 2: Summary of the number of genes in the community\n",
    "print(sign.iloc[:, 1].describe())  # Summarizing the gene count per community\n",
    "\n",
    "# Extract genes from the third column\n",
    "allgenes = []\n",
    "for i in range(len(fil_clust)):\n",
    "    genes_in_com = fil_clust.iloc[i, 2]\n",
    "    genes_in_com = genes_in_com.split(\" \")  # Splitting by space\n",
    "    allgenes.extend(genes_in_com)\n",
    "\n",
    "allgenes = list(map(lambda x: x[:15], allgenes))  # Restricting to 15 characters\n",
    "print(len(allgenes))  # Total genes\n",
    "print(len(set(allgenes)))  # Unique genes\n",
    "\n",
    "# Subset the annotation data for the genes in allgenes\n",
    "anno_sub = anno[anno.iloc[:, 1].isin(allgenes)]\n",
    "background = set(anno.iloc[:, 0])  # Using all genes as the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get go annotation\n",
    "# Connect to the Ensembl human dataset using BioMart\n",
    "dataset = Dataset(name='hsapiens_gene_ensembl', \n",
    "                  host='http://www.ensembl.org')\n",
    "\n",
    "# Query BioMart for GO terms\n",
    "gene_go_df = dataset.query(attributes=['ensembl_gene_id', 'go_id', 'hgnc_symbol'])\n",
    "\n",
    "# filter based on your list of genes \n",
    "gene_go_df = gene_go_df[gene_go_df['HGNC symbol'].isin(allgenes)]\n",
    "\n",
    "# remove any NAs\n",
    "gene_go_df_clean = gene_go_df.dropna(subset=['GO term accession'])\n",
    "\n",
    "print(gene_go_df_clean.head())  # Show the gene-to-GO mappings\n",
    "\n",
    "# Convert DataFrame to a dictionary {gene_id: set([go_id1, go_id2, ...])}\n",
    "gene_to_go_dict = gene_go_df_clean.groupby('Gene stable ID')['GO term accession'].apply(set).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run go enrichment\n",
    "godag = obo_parser.GODag(\"../data/go-basic.obo\") \n",
    "\n",
    "goea = GOEnrichmentStudy(\n",
    "        background, \n",
    "        gene_to_go_dict,  # Provide gene-to-GO mappings\n",
    "        godag, \n",
    "        propagate_counts=True,\n",
    "        methods=[\"bonferroni\",\"fdr_bh\"]\n",
    "    )\n",
    "    \n",
    "goea_results = goea.run_study(study=gene_go_df_clean['Gene stable ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing hierarchical clustering on community scores vs pathway scores\n",
    "SAMBAR already outputs some clustering, so here just plotting heatmaps with dendograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in clusters\n",
    "comm_clust = pd.read_csv(\"clustergroups_comm.csv\", delimiter=\",\")\n",
    "path_clust = pd.read_csv(\"clustergroups_path.csv\", delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "sns.clustermap(path_clust)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eland",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

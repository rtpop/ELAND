{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running \"ELAND\"\n",
    "This notebook runs what is currently the very bare bones of ELAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries & scripts\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bihidef\n",
    "import filter_panda\n",
    "from netZooPy import sambar\n",
    "#import sambar_adapted_fun\n",
    "from goatools import obo_parser\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "from collections import defaultdict\n",
    "from pybiomart import Dataset\n",
    "\n",
    "#set working directory\n",
    "os.chdir(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter network\n",
    "fil_edges = filter_panda.filter_edges(prior_file=\"../data/prior.txt\",panda_file=\"../data/panda_net.txt\")\n",
    "fil_edges.to_csv(\"../data/brca_fil_edges.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bihidef\n",
    "# this will save a bunch of files in the working directory\n",
    "bihidef.bihidef(\"../data/brca_fil_edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get communities\n",
    "sign = pd.read_csv(\"pvg.nodes\", delimiter = \"\\t\")\n",
    "\n",
    "# Extract clusters\n",
    "clusters = sign.iloc[:, 0].astype(str)\n",
    "clusters = clusters.str[7:]  # removing the first 7 characters\n",
    "clusters = np.array([list(map(int, c.split('-'))) for c in clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select clusters with sizes between selected range\n",
    "# set range\n",
    "min_size = 10\n",
    "max_size = 200\n",
    "\n",
    "fil_clust = sign[(sign.iloc[:,1] >= min_size) & (sign.iloc[:,1] <= max_size)]\n",
    "\n",
    "fil_clust.to_csv(\"fil_comm.gmt\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# trying to import bihidef output into sambar\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sambar_test \u001b[38;5;241m=\u001b[39m \u001b[43msambar\u001b[49m\u001b[38;5;241m.\u001b[39msambar(mut_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/BRCAmutMatrixFinal.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                             esize_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/esizef.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                             genes_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/genes.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                             gmtfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfil_comm.gmt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# trying to import bihidef output into sambar\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sambar_test \u001b[38;5;241m=\u001b[39m \u001b[43msambar\u001b[49m\u001b[38;5;241m.\u001b[39msambar(mut_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/BRCAmutMatrixFinal.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                             esize_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/esizef.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                             genes_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/genes.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                             gmtfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfil_comm.gmt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/eland/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eland/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trying to import bihidef output into sambar\n",
    "sambar_test = sambar.sambar(mut_file=\"../data/BRCAmutMatrixFinal.csv\",\n",
    "                            esize_file=\"../data/esizef.csv\",\n",
    "                            genes_file=\"../data/genes.txt\",\n",
    "                            gmtfile=\"fil_comm.gmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go enrichment for selected communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GTEx gene annotation file\n",
    "anno = pd.read_csv(\"../data/GTEx_gene_names.txt\", delimiter=\"\\t\")\n",
    "\n",
    "# Column 2: Summary of the number of genes in the community\n",
    "print(sign.iloc[:, 1].describe())  # Summarizing the gene count per community\n",
    "\n",
    "# Extract genes from the third column\n",
    "allgenes = []\n",
    "for i in range(len(fil_clust)):\n",
    "    genes_in_com = fil_clust.iloc[i, 2]\n",
    "    genes_in_com = genes_in_com.split(\" \")  # Splitting by space\n",
    "    allgenes.extend(genes_in_com)\n",
    "\n",
    "allgenes = list(map(lambda x: x[:15], allgenes))  # Restricting to 15 characters\n",
    "print(len(allgenes))  # Total genes\n",
    "print(len(set(allgenes)))  # Unique genes\n",
    "\n",
    "# Subset the annotation data for the genes in allgenes\n",
    "anno_sub = anno[anno.iloc[:, 1].isin(allgenes)]\n",
    "background = set(anno.iloc[:, 0])  # Using all genes as the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get go annotation\n",
    "# Connect to the Ensembl human dataset using BioMart\n",
    "dataset = Dataset(name='hsapiens_gene_ensembl', \n",
    "                  host='http://www.ensembl.org')\n",
    "\n",
    "# Query BioMart for GO terms\n",
    "gene_go_df = dataset.query(attributes=['ensembl_gene_id', 'go_id', 'hgnc_symbol'])\n",
    "\n",
    "# filter based on your list of genes \n",
    "gene_go_df = gene_go_df[gene_go_df['HGNC symbol'].isin(allgenes)]\n",
    "\n",
    "# remove any NAs\n",
    "gene_go_df_clean = gene_go_df.dropna(subset=['GO term accession'])\n",
    "\n",
    "print(gene_go_df.head())  # Show the gene-to-GO mappings\n",
    "\n",
    "# Convert DataFrame to a dictionary {gene_id: set([go_id1, go_id2, ...])}\n",
    "gene_to_go_dict = gene_go_df_clean.groupby('Gene stable ID')['GO term accession'].apply(set).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run go enrichment\n",
    "godag = obo_parser.GODag(\"../data/go-basic.obo\") \n",
    "\n",
    "goea = GOEnrichmentStudy(\n",
    "        background, \n",
    "        gene_to_go_dict,  # Provide gene-to-GO mappings\n",
    "        godag, \n",
    "        propagate_counts=True,\n",
    "        methods=[\"fdr_bh\"]\n",
    "    )\n",
    "    \n",
    "goea_results = goea.run_study()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eland",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
